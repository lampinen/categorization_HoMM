---
title: "Category analysis"
author: "Andrew Lampinen"
output: html_document
---

```{r}
library(tidyverse)
library(lme4)
library(lmerTest)
```

# data loading

```{r}
parent_dir = ".."
subdirs = c(
            "results_135"
            )

lang_subdirs = c("results_136/language", "results_135/language")
lang_homm_subdirs = c("results_135/language_HoMM")
num_runs = 5
```

```{r}
read_config = function(config_file) { 
  config = read_delim(config_file, delim="\n") %>%
    separate(`key, value`, c("key", "value"), sep=",", extra="merge") %>%
    spread(key, value) %>%
    mutate_at(c("base_train_tasks", "base_eval_tasks", "meta_class_train_tasks", "meta_class_eval_tasks", "meta_map_train_tasks", "meta_map_eval_tasks"), function(x) {
      x = gsub("\\\"|[][]| |\'", "", x)
      return(str_split(x, ","))
    } )
}
```

```{r}
load_d = function(results_dir, result_subdirs, num_runs, file_type) {
  d = replicate(num_runs * length(result_subdirs), data.frame())
  index = 1
  for (run_i in 0:(num_runs-1)) {
    for (result_subdir in result_subdirs) {
      filename = sprintf("%s/%s/run%i_%s.csv", results_dir, result_subdir, run_i, file_type)
      print(filename)
      if (!file.exists(filename)) {
        print(paste("skipping ", filename, sep=""))
        next
      }
      if (grepl("config", file_type)) {
        this_d = read_config(filename)
      } else {
        this_d = read.csv(filename, check.names=F, header=T) 
        names(this_d) <- make.unique(names(this_d)) 

      }
      this_d = this_d %>%
        mutate(run = run_i,
               run_type = result_subdir)
      d[[index]] = this_d
      index = index + 1
    }
    
  }
  d = bind_rows(d)
  return(d)
}
```

```{r}
config_d = load_d(parent_dir, subdirs, num_runs, "run_config")
loss_d = load_d(parent_dir, subdirs, num_runs, "losses")
lang_loss_d = load_d(parent_dir, lang_subdirs, num_runs, "language_losses")
meta_true_d = load_d(parent_dir, subdirs, num_runs, "meta_true_losses")
lang_meta_true_d = load_d(parent_dir, lang_homm_subdirs, num_runs, "language_meta_true_losses")
```

# some manipulation

```{r}
loss_d = loss_d %>%
  filter(epoch %% 100 == 0) %>%
  gather(task_and_train_or_eval, loss, -epoch, -run, -run_type) %>%
  separate(task_and_train_or_eval, c("task", "train_or_eval"), sep=":") %>%
  mutate(meta = grepl("is_|switch_|^NOT$", task),
         accuracy = grepl("accuracy", task),
         meta_task_type = case_when(!meta ~ "NA",
                                    task == "NOT" ~ "NOT",
                                    grepl("switch_color", task) ~ "switch_color",
                                    grepl("switch_shape", task) ~ "switch_shape",
                                    grepl("switch_size", task) ~ "switch_size"),
         composite = ifelse(grepl("AND|OR|XOR", task), "composite", "basic"),
         color_relevant = grepl("color", task),
         shape_relevant = grepl("shape", task),
         size_relevant = grepl("size", task))
  
```

```{r}
lang_loss_d = lang_loss_d %>%
  filter(epoch %% 100 == 0) %>%
  gather(task_and_train_or_eval, loss, -epoch, -run, -run_type) %>%
  separate(task_and_train_or_eval, c("task", "train_or_eval"), sep=":") %>%
  mutate(accuracy = grepl("accuracy", task),
         composite = ifelse(grepl("AND|OR|XOR", task), "composite", "basic"),
         composite_type = str_extract(task, "AND|OR|XOR"),
         color_relevant = grepl("color", task),
         shape_relevant = grepl("shape", task),
         size_relevant = grepl("size", task))
```


```{r}
meta_true_d = meta_true_d %>%
  filter(epoch %% 100 == 0) %>%
  gather(task, loss, -epoch, -run, -run_type) %>%
  separate(task, c("meta_task", "mapping_toe", "base_task_toe", "source", "target"), ":|->") %>%
  mutate(meta_task_type = case_when(meta_task == "NOT" ~ "NOT",
                                    grepl("switch_color", meta_task) ~ "switch_color",
                                    grepl("switch_shape", meta_task) ~ "switch_shape",
                                    grepl("switch_size", meta_task) ~ "switch_size"),
         base_task_type = case_when(grepl("AND|OR|XOR", source) ~ "composite",
                                    T ~ "basic"),
         base_composite_type = str_extract(source, "AND|OR|XOR"))
  
```

```{r}
lang_meta_true_d = lang_meta_true_d %>%
  filter(epoch %% 100 == 0) %>%
  gather(task, loss, -epoch, -run, -run_type) %>%
  separate(task, c("meta_task", "mapping_toe", "base_task_toe", "source", "target"), ":|->") %>%
  mutate(meta_task_type = case_when(meta_task == "NOT" ~ "NOT",
                                    grepl("switch_color", meta_task) ~ "switch_color",
                                    grepl("switch_shape", meta_task) ~ "switch_shape",
                                    grepl("switch_size", meta_task) ~ "switch_size"),
         base_task_type = case_when(grepl("AND|OR|XOR", source) ~ "composite",
                                    T ~ "basic"),
         base_composite_type = str_extract(source, "AND|OR|XOR"))
  
```


# basic plots
```{r}
theme_set(theme_classic())
```

```{r}
ggplot(loss_d %>% 
         filter(!meta),
       aes(x=epoch, y=loss, color=train_or_eval)) +
  geom_line(stat="summary",
            fun.y="mean") +
  facet_grid(run_type ~ accuracy, scales="free") 
```

```{r}
ggplot(loss_d %>% 
         filter(!meta,
                accuracy,
                run_type == "results_135"),
       aes(x=epoch, y=loss, color=train_or_eval)) +
  geom_line(stat="summary",
            fun.y="mean") +
  facet_grid(shape_relevant + color_relevant + size_relevant ~ composite + accuracy, scales="free") 
```


```{r}
ggplot(loss_d %>%
         filter(meta),
       aes(x=epoch, y=loss, color=train_or_eval)) +
  geom_line(stat="summary",
            fun.y="mean") +
  facet_grid(run_type ~ meta_task_type, scales="free") 
```

```{r}
ggplot(meta_true_d %>%
         filter(run_type == "results_135"),
       aes(x=epoch, y=loss, color=base_task_toe, linetype=mapping_toe)) +
  geom_line(stat="summary",
            fun.y="mean") +
  facet_grid(run ~ base_task_type + run_type, scales="free")
```

```{r}
# ggplot(meta_true_d %>%
#          filter(!grepl("results_135", run_type)),
#        aes(x=epoch, y=loss, color=base_task_toe, linetype=mapping_toe)) +
#   geom_line(stat="summary",
#             fun.y="mean") +
#   facet_grid(run ~ base_task_type + run_type, scales="free")
```

```{r}
ggplot(lang_meta_true_d,
       aes(x=epoch, y=loss, color=base_task_toe, linetype=mapping_toe)) +
  geom_line(stat="summary",
            fun.y="mean") +
  facet_grid(run ~ base_task_type + run_type, scales="free")
```

# language baseline

```{r}
ggplot(lang_loss_d %>%
         filter(accuracy,
                grepl("136", run_type)),
       
       aes(x=epoch, y=loss, color=train_or_eval)) +
  geom_line(stat="summary",
            fun.y="mean") +
  facet_grid(run_type + color_relevant + shape_relevant + size_relevant ~ composite + composite_type, scales="free") 
```

```{r}
ggplot(lang_loss_d %>%
         filter(accuracy,
                grepl("136", run_type)),
       aes(x=epoch, y=loss, color=train_or_eval)) +
  geom_line(stat="summary",
            fun.y="mean") +
  facet_wrap(~run)
```

```{r}
ggplot(lang_loss_d %>%
         filter(accuracy,
                grepl("136", run_type)),
       aes(x=epoch, y=loss, color=train_or_eval)) +
  geom_line(stat="summary",
            fun.y="mean") 
```


# head to head comparison on harder tasks

```{r}
ggplot(lang_loss_d %>%
         filter(accuracy,
                composite == "composite",
                composite_type %in% c("AND", "XOR"),
                grepl("136", run_type)),
       aes(x=epoch, y=loss, color=train_or_eval)) +
  
  geom_hline(yintercept=0.9) +
  geom_line(stat="summary",
            fun.y="mean")
``` 


```{r}
ggplot(meta_true_d %>%
         filter(base_composite_type %in% c("AND", "XOR"), 
                run_type == "results_135"),
       aes(x=epoch, y=loss, color=base_task_toe, linetype=mapping_toe)) +
  geom_line(stat="summary",
            fun.y="mean") +
  facet_wrap(run ~meta_task_type)
```
```{r}
ggplot(lang_meta_true_d %>%
         filter(base_composite_type %in% c("AND", "XOR"), 
                grepl("135", run_type)),
       aes(x=epoch, y=loss, color=base_task_toe, linetype=mapping_toe)) +
  geom_line(stat="summary",
            fun.y="mean") +
  geom_hline(yintercept=0.9) +
  facet_wrap(run ~ meta_task_type)
```

# comparison

Some tasks may not appear as result of meta-mapping
```{r}
target_tasks_by_run =  meta_true_d %>%
  filter(epoch == 0,
         base_task_toe == "example_is_eval",
         mapping_toe == "metamapping_is_train",
         base_composite_type %in% c("AND", "XOR"), 
         grepl("135", run_type),
         !is.na(loss)) %>%
  select(run, source, target) %>%
  select(-source) %>%
  rename(task=target) %>%
  distinct()
```

These results are robust to choice of test epoch (as long as it is large enough for learning to have asymptoted).

```{r}
test_epoch = 5000
comparison_d = bind_rows(lang_loss_d %>%
                           filter(accuracy,
                                  train_or_eval == "eval",
                                  composite == "composite",
                                  composite_type %in% c("AND", "XOR"),
                                  grepl("136", run_type),
                                  !is.na(loss)) %>%
                           mutate(task = gsub("_accuracy", "", task)) %>%
                           select(epoch, run, run_type, task, loss) %>%
                           inner_join(target_tasks_by_run) %>%
                           group_by(run_type, run, epoch) %>%
                           summarise(mean_accuracy = mean(loss, na.rm=T)) %>%
#                           group_by(run_type, run) %>%
#                           filter(mean_accuracy == max(mean_accuracy)) %>%
                           filter(epoch == test_epoch) %>%
                           ungroup(),
                         meta_true_d %>%
                           filter(base_task_toe == "example_is_eval",
                                  mapping_toe == "metamapping_is_train",
                                  base_composite_type %in% c("AND", "XOR"), 
                                  grepl("135", run_type)) %>%
                           group_by(run_type, run, epoch, target) %>%   # multiple mappings may produce same target                          
                           summarise(accuracy = mean(loss, na.rm=T)) %>%
                           group_by(run_type, run, epoch) %>%                           
                           summarise(mean_accuracy = mean(accuracy, na.rm=T)) %>%
#                           group_by(run_type, run) %>%
#                           filter(mean_accuracy == max(mean_accuracy)) %>%
                           filter(epoch == test_epoch) %>%
                           ungroup(),
                         lang_meta_true_d %>%
                           filter(base_task_toe == "example_is_eval",
                                  mapping_toe == "metamapping_is_train",
                                  base_composite_type %in% c("AND", "XOR"), 
                                  grepl("135", run_type)) %>%
                           group_by(run_type, run, epoch, target) %>%   # multiple mappings may produce same target                          
                           summarise(accuracy = mean(loss, na.rm=T)) %>%
                           group_by(run_type, run, epoch) %>%                           
                           summarise(mean_accuracy = mean(accuracy, na.rm=T)) %>%
                           # group_by(run_type, run) %>%
                           # filter(mean_accuracy == max(mean_accuracy)) %>%
                           filter(epoch == test_epoch) %>%
                           ungroup()) %>%
  mutate(run_type = case_when(grepl("language_HoMM", run_type) ~ "Lang_HoMM",
                              grepl("language", run_type) ~ "Lang",
                              T ~ "HoMM from examples"),
         run_type = factor(run_type,
                           levels=c("HoMM from examples", "Lang", "Lang_HoMM"),
                           labels=c("HoMM from examples", "Language", "HoMM from language")))
```

## some quick tests

```{r}
perm_mean_diff_test = function(x, y, alpha=0.05) {
  obs_t = t.test(x, y)$statistic
  combined_data = c(x, y)
  n_combined = length(combined_data)
  n_x = length(x)
  perm_iterate = function(x, y) {
    perm = sample(n_combined)
    x_samp = combined_data[perm[1:n_x]]
    y_samp = combined_data[perm[-(1:n_x)]]
    this_t = t.test(x_samp, y_samp)$statistic
    return(this_t)
  }
  perms = replicate(500, perm_iterate(x, y))
  quants = quantile(perms, probs=c(alpha/2, 1-alpha/2))
  return(obs_t < quants[1] | obs_t > quants[2])
}
```

```{r}
set.seed(0)  # reproducibility
perm_mean_diff_test(
  comparison_d %>%
    filter(run_type == "HoMM from examples") %>%
    pull(mean_accuracy),
  comparison_d %>%
    filter(run_type == "Language") %>%
    pull(mean_accuracy)
)

perm_mean_diff_test(
  comparison_d %>%
    filter(run_type == "HoMM from examples") %>%
    pull(mean_accuracy),
  comparison_d %>%
    filter(run_type == "HoMM from language") %>%
    pull(mean_accuracy)
)

perm_mean_diff_test(
  comparison_d %>%
    filter(run_type == "Language") %>%
    pull(mean_accuracy),
  comparison_d %>%
    filter(run_type == "HoMM from language") %>%
    pull(mean_accuracy)
)
```

```{r}
contrasts(comparison_d$run_type) = cbind(HoMM=c(1, 0, 0), LangHoMM=c(0, 0, 1))
lm(mean_accuracy~ run_type,
   comparison_d) %>%
  summary()
lmer(mean_accuracy~ run_type + (1| run),
     comparison_d) %>%
  summary()

```

```{r}
set.seed(0)
comparison_d %>% 
  group_by(run_type) %>%
  do(results=mean_cl_boot(.$mean_accuracy)) %>%
  mutate(y=results$y,
         ymin=results$ymin,
         ymax=results$ymax)
```

## and a plot

```{r}
ggplot(data=comparison_d %>%
         filter(run_type != "HoMM from language"),
       aes(x=run_type, 
           color=run_type,
           y=mean_accuracy)) +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_errorbar(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1) +
  geom_point(stat="summary",
             fun.y="mean",
             size=4) +
  scale_color_manual(values=c("#e41a1c", "#477ec8", "#984ea3")) +
  labs(x="Model type", y="Accuracy") +
  annotate("text", x=0.6, y=0.52, alpha=0.5, label="Chance") +
  annotate("text", x=0.7, y=1.02, alpha=0.5, label="Optimal adaptation") +
  annotate("path",x=c(1,1,2,2),y=c(1.05,1.08,1.08,1.05),alpha=0.5) +
  annotate("text", x=1.5, y=1.1, alpha=0.5, label="n.s. (both perm- and t-test)") +
  scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%")) +
  guides(color=F)

#ggsave("../../../assorted_talks/HoMM/figures/categories_adaptation_no_lh.png", width=6, height=4)
```



```{r}
ggplot(data=comparison_d,
       aes(x=run_type, 
           color=run_type,
           y=mean_accuracy)) +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_errorbar(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1) +
  geom_point(stat="summary",
             fun.y="mean",
             size=4) +
  scale_color_manual(values=c("#e41a1c", "#477ec8", "#984ea3")) +
  labs(x="Model type", y="Accuracy on evaluation tasks") +
  annotate("text", x=0.6, y=0.52, alpha=0.5, label="Chance") +
  annotate("text", x=0.85, y=1.02, alpha=0.5, label="Optimal adaptation") +
  annotate("path",x=c(1,1,1.95,1.95),y=c(1.05,1.08,1.08,1.05),alpha=0.5) +
  annotate("text", x=1.5, y=1.1, alpha=0.5, label="n.s. (both perm- and t-test)") +
  annotate("path",x=c(2.05, 2.05, 3, 3),y=c(1.05,1.08,1.08,1.05),alpha=0.5) +
  annotate("text", x=2.5, y=1.1, alpha=0.5, label="p < 0.05 (both tests)") +
  scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%")) +
  guides(color=F)

#ggsave("../../../assorted_talks/HoMM/figures/categories_adaptation.png", width=6, height=4)
#ggsave("../../../psych/dissertation/4-extending/figures/concepts_adaptation.png", width=6, height=4)
```

```{r}
ggplot(data=comparison_d %>% 
         filter(!grepl("examples", run_type)),
       aes(x=run_type, 
           color=run_type,
           y=mean_accuracy)) +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_errorbar(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1) +
  geom_point(stat="summary",
             fun.y="mean",
             size=4) +
  scale_color_manual(values=c("#477ec8", "#984ea3")) +
  labs(x="Model type", y="Accuracy on evaluation tasks") +
  annotate("text", x=0.6, y=0.52, alpha=0.5, label="Chance") +
  annotate("text", x=0.7, y=1.02, alpha=0.5, label="Optimal adaptation") +
  annotate("path",x=c(1,1,2,2),y=c(1.05,1.08,1.08,1.05),alpha=0.5) +
  annotate("text", x=1.5, y=1.1, alpha=0.5, label="p < 0.05") +
  scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%")) +
  guides(color=F)

#ggsave("../../../psych/dissertation/4-extending/figures/concepts_adaptation_language_only.png", width=6, height=4)
```

MM paper plot
```{r}
ggplot(data=comparison_d %>% 
         filter(!grepl("examples", run_type)) %>%
         mutate(run_type = factor(run_type, levels=c("HoMM from language", "Language"), labels=c("Meta-mapping\n(from language)", "Language\nalone"))),
       aes(x=run_type, 
           color=run_type,
           y=mean_accuracy)) +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  #geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_errorbar(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1) +
  geom_point(stat="summary",
             fun.y="mean",
             size=3) +
  #scale_color_manual(values=c("#e41a1c", "#477ec8")) +
  scale_color_manual(values=c("#fec44f", "#02205b")) +
  labs(x="Model type", y="Adapted concept eval. accuracy\n(trained MMs)") +
  #annotate("text", x=0.62, y=0.53, alpha=0.5, label="Chance") +
  annotate("text", x=0.62, y=1.007, alpha=0.5, label="Optimal") +
  annotate("path",x=c(1,1,2,2),y=c(1.005,1.01,1.01,1.005),alpha=0.5) +
  annotate("text", x=1.5, y=1.017, alpha=0.5, label="p < 0.05") +
  scale_y_continuous(breaks = c(0.9, 0.95, 1), labels = c("90%", "95%", "100%")) +
  guides(color=F)

ggsave("../../metamapping_paper/figures/concepts_adaptation_random_tasks.png", width=4, height=3)
```

## validating the language model architecture

```{r}
lang_arch_d = lang_loss_d %>%
  filter(accuracy,
         train_or_eval == "eval",
         composite == "composite",
         composite_type %in% c("AND", "XOR"),
         !is.na(loss)) %>%
  mutate(task = gsub("_accuracy", "", task)) %>%
  select(epoch, run, run_type, task, loss) %>%
  inner_join(target_tasks_by_run) %>%
  group_by(run_type, run, epoch) %>%
  summarise(mean_accuracy = mean(loss, na.rm=T)) %>%
  filter(epoch == test_epoch) %>%
  ungroup() %>%
  mutate(task_network = factor(run_type, labels=c("Linear (used for HoMM)", "Multi-layer nonlinear")))
```
```{r}
set.seed(0)
perm_mean_diff_test(
  lang_arch_d %>%
    filter(grepl("135", run_type)) %>%
    pull(mean_accuracy),
  lang_arch_d %>%
    filter(grepl("136", run_type)) %>%
    pull(mean_accuracy)
)

lmer(mean_accuracy~ run_type + (1| run),
     lang_arch_d) %>%
  summary()
```
```{r}
set.seed(0)
lang_arch_d %>% 
  group_by(task_network) %>%
  do(results=mean_cl_boot(.$mean_accuracy)) %>%
  summarize(y=results$y,
            ymin=results$ymin,
            ymax=results$ymax)
```

```{r}
ggplot(data=lang_arch_d,
       aes(x=task_network, 
           color=task_network,
           y=mean_accuracy)) +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_errorbar(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1) +
  geom_point(stat="summary",
             fun.y="mean",
             size=4) +
  scale_color_manual(values=c("#477ec8", "#02205b")) +
  labs(x="Task network architecture", y="Language generalization accuracy") +
  annotate("text", x=0.6, y=0.52, alpha=0.5, label="Chance") +
  annotate("text", x=0.6, y=1.02, alpha=0.5, label="Optimal") +
  annotate("path",x=c(1,1,2,2),y=c(1.05,1.08,1.08,1.05),alpha=0.5) +
  annotate("text", x=1.5, y=1.1, alpha=0.5, label="p < 0.05") +
  scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%")) +
  guides(color=F)

ggsave("../../metamapping_paper/figures/concepts_language_model_architecture_justification.png", width=4, height=3)
#ggsave("../../../psych/dissertation/4-extending/figures/language_model_architecture_justification.png", width=6, height=4)
```



# now the eval comparison
```{r}
eval_target_tasks_by_run =  meta_true_d %>%
  filter(epoch == 0,
         base_task_toe == "example_is_eval",
         mapping_toe == "metamapping_is_eval",
         base_composite_type %in% c("AND", "XOR"), 
         grepl("135", run_type),
         !is.na(loss)) %>%
  select(run, source, target) %>%
  select(-source) %>%
  rename(task=target) %>%
  distinct()
```

These results are going to vary more with test epoch, because the results are noisy. Using the same as above to avoid p-hacking, but in fact generalization appears to be better earlier in learning on the whole.

```{r}
test_epoch = 5000
eval_comparison_d = bind_rows(lang_loss_d %>%
                           filter(accuracy,
                                  train_or_eval == "eval",
                                  composite == "composite",
                                  composite_type %in% c("AND", "XOR"),
                                  grepl("136", run_type),
                                  !is.na(loss)) %>%
                           mutate(task = gsub("_accuracy", "", task)) %>%
                           select(epoch, run, run_type, task, loss) %>%
                           inner_join(eval_target_tasks_by_run) %>%
                           group_by(run_type, run, epoch) %>%
                           summarise(mean_accuracy = mean(loss, na.rm=T)) %>%
#                           group_by(run_type, run) %>%
#                           filter(mean_accuracy == max(mean_accuracy)) %>%
                           filter(epoch == test_epoch) %>%
                           ungroup(),
                         meta_true_d %>%
                           filter(base_task_toe == "example_is_eval",
                                  mapping_toe == "metamapping_is_eval",
                                  base_composite_type %in% c("AND", "XOR"), 
                                  grepl("135", run_type)) %>%
                           group_by(run_type, run, epoch, target) %>%   # multiple mappings may produce same target                          
                           summarise(accuracy = mean(loss, na.rm=T)) %>%
                           group_by(run_type, run, epoch) %>%                           
                           summarise(mean_accuracy = mean(accuracy, na.rm=T)) %>%
#                           group_by(run_type, run) %>%
#                           filter(mean_accuracy == max(mean_accuracy)) %>%
                           filter(epoch == test_epoch) %>%
                           ungroup(),
                         lang_meta_true_d %>%
                           filter(base_task_toe == "example_is_eval",
                                  mapping_toe == "metamapping_is_eval",
                                  base_composite_type %in% c("AND", "XOR"), 
                                  grepl("135", run_type)) %>%
                           group_by(run_type, run, epoch, target) %>%   # multiple mappings may produce same target                          
                           summarise(accuracy = mean(loss, na.rm=T)) %>%
                           group_by(run_type, run, epoch) %>%                           
                           summarise(mean_accuracy = mean(accuracy, na.rm=T)) %>%
                           # group_by(run_type, run) %>%
                           # filter(mean_accuracy == max(mean_accuracy)) %>%
                           filter(epoch == test_epoch) %>%
                           ungroup()) %>%
  mutate(run_type = case_when(grepl("language_HoMM", run_type) ~ "Lang_HoMM",
                              grepl("language", run_type) ~ "Lang",
                              T ~ "HoMM from examples"),
         run_type = factor(run_type,
                           levels=c("HoMM from examples", "Lang", "Lang_HoMM"),
                           labels=c("HoMM from examples", "Language", "HoMM from language")))
```

## some quick tests

```{r}
set.seed(0)  # reproducibility
perm_mean_diff_test(
  eval_comparison_d %>%
    filter(run_type == "HoMM from examples") %>%
    pull(mean_accuracy),
  eval_comparison_d %>%
    filter(run_type == "Language") %>%
    pull(mean_accuracy)
)

perm_mean_diff_test(
  eval_comparison_d %>%
    filter(run_type == "HoMM from examples") %>%
    pull(mean_accuracy),
  eval_comparison_d %>%
    filter(run_type == "HoMM from language") %>%
    pull(mean_accuracy)
)

perm_mean_diff_test(
  eval_comparison_d %>%
    filter(run_type == "Language") %>%
    pull(mean_accuracy),
  eval_comparison_d %>%
    filter(run_type == "HoMM from language") %>%
    pull(mean_accuracy)
)
```

```{r}
contrasts(eval_comparison_d$run_type) = cbind(HoMM=c(1, 0, 0), LangHoMM=c(0, 0, 1))
lm(mean_accuracy~ run_type,
   eval_comparison_d) %>%
  summary()
```


## and a plot

```{r}
ggplot(data=eval_comparison_d %>%
         filter(run_type != "HoMM from language"),
       aes(x=run_type, 
           color=run_type,
           y=mean_accuracy)) +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_errorbar(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1) +
  geom_point(stat="summary",
             fun.y="mean",
             size=4) +
  scale_color_manual(values=c("#e41a1c", "#477ec8", "#984ea3")) +
  labs(x="Model type", y="Accuracy") +
  annotate("text", x=0.6, y=0.52, alpha=0.5, label="Chance") +
  annotate("text", x=0.7, y=1.02, alpha=0.5, label="Optimal adaptation") +
  annotate("path",x=c(1,1,2,2),y=c(1.05,1.08,1.08,1.05),alpha=0.5) +
  annotate("text", x=1.5, y=1.1, alpha=0.5, label="n.s. (both perm- and t-test)") +
  scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%")) +
  guides(color=F)

#ggsave("../../../assorted_talks/HoMM/figures/categories_adaptation_no_lh.png", width=6, height=4)
```



```{r}
ggplot(data=eval_comparison_d,
       aes(x=run_type, 
           color=run_type,
           y=mean_accuracy)) +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_errorbar(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1) +
  geom_point(stat="summary",
             fun.y="mean",
             size=4) +
  scale_color_manual(values=c("#e41a1c", "#477ec8", "#984ea3")) +
  labs(x="Model type", y="Accuracy on held-out meta-mapping evaluation tasks") +
  annotate("text", x=0.6, y=0.52, alpha=0.5, label="Chance") +
  annotate("text", x=0.85, y=1.02, alpha=0.5, label="Optimal adaptation") +
  annotate("text", x=2, y=1.05, alpha=0.5, label="all comparisons n.s. (both perm- and t-test)") +
  scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%")) +
  guides(color=F)

#ggsave("../../../assorted_talks/HoMM/figures/categories_adaptation.png", width=6, height=4)
ggsave("../../../psych/dissertation/4-extending/figures/concepts_adaptation_eval_mappings.png", width=6, height=4)
```
