---
title: "Category analysis"
author: "Andrew Lampinen"
output: html_document
---

```{r}
library(tidyverse)
library(lme4)
```

# data loading

```{r}
parent_dir = "../categorization_HoMM_better_smaller_size_sweep"
subdirs = c(
            
            "results_nmappingsper_2",
            "results_nmappingsper_4",
            "results_nmappingsper_8",
            "results_nmappingsper_12",
            "results_nmappingsper_16"
            
            )

lang_subdirs = paste(subdirs, "language", sep="/")
lang_homm_subdirs = paste(subdirs, "language_HoMM", sep="/")
num_runs = 10
```

```{r}
read_config = function(config_file) { 
  config = read_delim(config_file, delim="\n") %>%
    separate(`key, value`, c("key", "value"), sep=",", extra="merge") %>%
    spread(key, value) %>%
    mutate_at(c("base_train_tasks", "base_eval_tasks", "meta_class_train_tasks", "meta_class_eval_tasks", "meta_map_train_tasks", "meta_map_eval_tasks"), function(x) {
      x = gsub("\\\"|[][]| |\'", "", x)
      return(str_split(x, ","))
    } )
}
```

```{r}
load_d = function(results_dir, result_subdirs, num_runs, file_type) {
  d = replicate(num_runs * length(result_subdirs), data.frame())
  index = 1
  for (run_i in 0:(num_runs-1)) {
    for (result_subdir in result_subdirs) {
      filename = sprintf("%s/%s/run%i_%s.csv", results_dir, result_subdir, run_i, file_type)
      print(filename)
      if (!file.exists(filename)) {
        print(paste("skipping ", filename, sep=""))
        next
      }
      if (grepl("config", file_type)) {
        this_d = read_config(filename)
      } else {
        this_d = read.csv(filename, check.names=F, header=T) 
        names(this_d) <- make.unique(names(this_d)) 

      }
      this_d = this_d %>%
        mutate(run = run_i,
               run_type = result_subdir)
      d[[index]] = this_d
      index = index + 1
    }
    
  }
  d = bind_rows(d)
  return(d)
}
```

```{r}
config_d = load_d(parent_dir, subdirs, num_runs, "run_config")
#loss_d = load_d(parent_dir, subdirs, num_runs, "losses")
lang_loss_d = load_d(parent_dir, lang_subdirs, num_runs, "language_losses")
#meta_true_d = load_d(parent_dir, subdirs, num_runs, "meta_true_losses")
lang_meta_true_d = load_d(parent_dir, lang_homm_subdirs, num_runs, "language_meta_true_losses")
```

# some manipulation

```{r}
# loss_d = loss_d %>%
#   filter(epoch %% 100 == 0) %>%
#   gather(task_and_train_or_eval, loss, -epoch, -run, -run_type) %>%
#   separate(task_and_train_or_eval, c("task", "train_or_eval"), sep=":") %>%
#   mutate(meta = grepl("is_|switch_|^NOT$", task),
#          accuracy = grepl("accuracy", task),
#          meta_task_type = case_when(!meta ~ "NA",
#                                     task == "NOT" ~ "NOT",
#                                     grepl("switch_color", task) ~ "switch_color",
#                                     grepl("switch_shape", task) ~ "switch_shape",
#                                     grepl("switch_size", task) ~ "switch_size"),
#          composite = ifelse(grepl("AND|OR|XOR", task), "composite", "basic"),
#          color_relevant = grepl("color", task),
#          shape_relevant = grepl("shape", task),
#          size_relevant = grepl("size", task),
#          num_train_examples = as.numeric(str_extract(run_type, "\\d+")),
#          train_or_eval=gsub("\\.\\d+", "", train_or_eval))
#   
```

```{r}
lang_loss_d = lang_loss_d %>%
  filter(epoch %% 100 == 0) %>%
  gather(task_and_train_or_eval, loss, -epoch, -run, -run_type) %>%
  separate(task_and_train_or_eval, c("task", "train_or_eval"), sep=":") %>%
  mutate(accuracy = grepl("accuracy", task),
         composite = ifelse(grepl("AND|OR|XOR", task), "composite", "basic"),
         composite_type = str_extract(task, "AND|OR|XOR"),
         color_relevant = grepl("color", task),
         shape_relevant = grepl("shape", task),
         size_relevant = grepl("size", task),
         num_train_examples = as.numeric(str_extract(run_type, "\\d+")),
         train_or_eval=gsub("\\.\\d+", "", train_or_eval))
```


```{r}
# meta_true_d = meta_true_d %>%
#   filter(epoch %% 100 == 0) %>%
#   gather(task, loss, -epoch, -run, -run_type) %>%
#   separate(task, c("meta_task", "mapping_toe", "base_task_toe", "source", "target"), ":|->") %>%
#   mutate(meta_task_type = case_when(meta_task == "NOT" ~ "NOT",
#                                     grepl("switch_color", meta_task) ~ "switch_color",
#                                     grepl("switch_shape", meta_task) ~ "switch_shape",
#                                     grepl("switch_size", meta_task) ~ "switch_size"),
#          base_task_type = case_when(grepl("AND|OR|XOR", source) ~ "composite",
#                                     T ~ "basic"),
#          base_composite_type = str_extract(source, "AND|OR|XOR"),
#          num_train_examples = as.numeric(str_extract(run_type, "\\d+")))
#   
```

```{r}
lang_meta_true_d = lang_meta_true_d %>%
  filter(epoch %% 100 == 0) %>%
  gather(task, loss, -epoch, -run, -run_type) %>%
  separate(task, c("meta_task", "mapping_toe", "base_task_toe", "source", "target"), ":|->") %>%
  mutate(meta_task_type = case_when(meta_task == "NOT" ~ "NOT",
                                    grepl("switch_color", meta_task) ~ "switch_color",
                                    grepl("switch_shape", meta_task) ~ "switch_shape",
                                    grepl("switch_size", meta_task) ~ "switch_size"),
         base_task_type = case_when(grepl("AND|OR|XOR", source) ~ "composite",
                                    T ~ "basic"),
         base_composite_type = str_extract(source, "AND|OR|XOR"),
         num_train_examples = as.numeric(str_extract(run_type, "\\d+")))

```

```{r}
theme_set(theme_classic())
```

```{r}
ggplot(lang_meta_true_d %>%
         filter(
                base_task_type == "composite",
                base_composite_type %in% c("AND", "XOR"),
                mapping_toe == "metamapping_is_train"),
       aes(x=epoch,
           y=loss,
           color=factor(base_task_toe, levels=c("example_is_train", "example_is_eval"), labels=c("Trained\ntarget", "Held-out\ntarget")))) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1) +
  facet_grid(I(2*num_train_examples) ~ run) +
  scale_x_continuous(limits=c(0, 10000), breaks=c(0, 5000, 10000), labels=c("0", "5", "10")) +
  scale_color_manual(values=c("#1b9e77", "#e7298a")) +
  labs(x="Epoch (thousands)", y="Average evaluation accuracy")+
  guides(color=guide_legend(title=NULL))

ggsave("../../metamapping_paper/figures/concepts_all_runs_train.png", width=8, height=5)
```

```{r}
ggplot(lang_meta_true_d %>%
         filter(
                base_task_type == "composite",
                base_composite_type %in% c("AND", "XOR"),
                mapping_toe == "metamapping_is_eval",
                base_task_toe == "example_is_eval"
                ),
       aes(x=epoch,
           y=loss,
           color=factor(base_task_toe, levels=c("example_is_train", "example_is_eval"), labels=c("Trained\ntarget", "Held-out\ntarget")))) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1) +
  facet_grid(I(2*num_train_examples) ~ run) +
  scale_x_continuous(limits=c(0, 10000), breaks=c(0, 5000, 10000), labels=c("0", "5", "10")) +
  scale_color_manual(values=c("#1b9e77", "#e7298a"), drop=F) +
  labs(x="Epoch (thousands)", y="Average evaluation accuracy")+
  guides(color=guide_legend(title=NULL))

ggsave("../../metamapping_paper/figures/concepts_all_runs_eval.png", width=8, height=5)
```

# comparison

Some tasks may not appear as result of meta-mapping
```{r}
target_tasks_by_run = bind_rows(
  lang_meta_true_d %>%
    filter(epoch == 0,
           base_task_toe == "example_is_eval",
           base_composite_type %in% c("AND", "XOR"), 
           !is.na(loss)) %>%
    mutate(num_train_examples = as.numeric(str_extract(run_type, "\\d+"))) %>%
    select(num_train_examples, run, mapping_toe, target) %>%
    rename(task=target)#,
  # meta_true_d %>%
  #   filter(epoch == 0,
  #          base_task_toe == "example_is_eval",
  #          base_composite_type %in% c("AND", "XOR"), 
  #          !is.na(loss)) %>%
  #   mutate(num_train_examples = as.numeric(str_extract(run_type, "\\d+"))) %>%
  #   select(num_train_examples, run, mapping_toe, target) %>%
  #   rename(task=target)
  )%>%
  distinct()
```

These results are robust to choice of test epoch (as long as it is large enough for learning to have asymptoted). Because different training sizes asymptote at different places, we test at a later epoch for smaller training sets.

```{r}
test_epoch = function(num_train_examples) {
  test_epoch = case_when(
    num_train_examples == 2 ~ 10000,
    num_train_examples == 4 ~ 7500,
    # num_train_examples == 8 ~ 5000,
    # num_train_examples == 12 ~ 5000,
    T ~ 5000
  ) 
  return(test_epoch)
}

comparison_d = bind_rows(lang_loss_d %>%
                           filter(accuracy,
                                  train_or_eval == "eval",
                                  composite == "composite",
                                  composite_type %in% c("AND", "XOR"),
                                  !is.na(loss)) %>%
                           filter(epoch == test_epoch(num_train_examples)) %>%
                           mutate(task = gsub("_accuracy", "", task)) %>%
                           select(epoch, run_type, num_train_examples, run, task, loss) %>%
                           inner_join(target_tasks_by_run) %>%
                           group_by(run_type, num_train_examples, mapping_toe, run, epoch) %>%
                           summarise(mean_accuracy = mean(loss, na.rm=T)) %>%
                           ungroup(),
#                          meta_true_d %>%
#                            filter(base_task_toe == "example_is_eval",
#                                   base_composite_type %in% c("AND", "XOR")) %>%
#                            filter(epoch == test_epoch(num_train_examples)) %>%
#                            group_by(run_type, num_train_examples, mapping_toe, run, epoch, target) %>%   # multiple mappings may produce same target                          
#                            summarise(accuracy = mean(loss, na.rm=T)) %>%
#                            group_by(run_type, num_train_examples, mapping_toe, run, epoch) %>%                           
#                            summarise(mean_accuracy = mean(accuracy, na.rm=T)) %>%
# #                           group_by(run_type, run) %>%
# #                           filter(mean_accuracy == max(mean_accuracy)) %>%
#                            ungroup(),
                         lang_meta_true_d %>%
                           filter(base_task_toe == "example_is_eval",
                                  base_composite_type %in% c("AND", "XOR")) %>%
                           filter(epoch == test_epoch(num_train_examples)) %>%
                           group_by(run_type, num_train_examples, mapping_toe, run, epoch, target) %>%   # multiple mappings may produce same target                          
                           summarise(accuracy = mean(loss, na.rm=T)) %>%
                           group_by(run_type, mapping_toe, run, epoch) %>%                           
                           summarise(mean_accuracy = mean(accuracy, na.rm=T)) %>%
                           ungroup()) %>%
  mutate(num_train_examples = as.numeric(str_extract(run_type, "\\d+")),
         run_type = case_when(grepl("language_HoMM", run_type) ~ "Lang_HoMM",
                              grepl("language", run_type) ~ "Lang",
                              T ~ "HoMM from examples"),
         run_type = factor(run_type,
                           levels=c("HoMM from examples", "Lang", "Lang_HoMM"),
                           labels=c("HoMM from examples", "Language", "HoMM from language")),
         )
```

## some quick tests

```{r}
lmer(mean_accuracy ~ run_type + scale(num_train_examples) + (1|run),
      data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train",
                run_type != "HoMM from examples") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language\nGeneralization"))) %>%
  summary()
```

```{r}
lmer(mean_accuracy ~ run_type + (1|run),
      data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train",
                num_train_examples == 8,
                run_type != "HoMM from examples") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language\nGeneralization"))) %>%
  summary()
```

```{r}
lmer(mean_accuracy ~ run_type + (1|run),
      data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train",
                num_train_examples == 12,
                run_type != "HoMM from examples") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language\nGeneralization"))) %>%
  summary()
```

## and a plot


```{r}
# ggplot(data=comparison_d %>%
#          filter(mapping_toe == "metamapping_is_train"),
#        aes(x=num_train_examples, 
#            color=run_type,
#            y=mean_accuracy)) +
#   geom_hline(yintercept=1, linetype=2, alpha=0.5) +
#   geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
#   geom_errorbar(stat="summary",
#                 fun.data="mean_cl_boot",
#                 width=0.25,
#                 size=1) +
#   geom_point(stat="summary",
#              fun.y="mean",
#              size=4) +
#   geom_line(stat="summary",
#             fun.y="mean",
#             size=1) +
#   scale_color_manual(values=c("#e41a1c", "#477ec8", "#984ea3")) +
#   labs(x="Number of training meta-mappings", y="Accuracy on evaluation tasks") +
#   # annotate("text", x=0.6, y=0.52, alpha=0.5, label="Chance") +
#   # annotate("text", x=0.85, y=1.02, alpha=0.5, label="Optimal adaptation") +
#   # annotate("path",x=c(1,1,1.95,1.95),y=c(1.05,1.08,1.08,1.05),alpha=0.5) +
#   # annotate("text", x=1.5, y=1.1, alpha=0.5, label="n.s. (both perm- and t-test)") +
#   # annotate("path",x=c(2.05, 2.05, 3, 3),y=c(1.05,1.08,1.08,1.05),alpha=0.5) +
#   # annotate("text", x=2.5, y=1.1, alpha=0.5, label="p < 0.05 (both tests)") +
#   scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%"))

#ggsave("../../../psych/dissertation/4-extending/figures/concepts_adaptation_sweeping.png", width=6, height=4)
```

MM paper version will not show examples comparions:

```{r}
ggplot(data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train" | run_type == "HoMM from language",
                run_type != "HoMM from examples") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language"),
                mapping_toe = factor(mapping_toe, levels = c("metamapping_is_train", "metamapping_is_eval"),
                                     labels = c("TrainedMM",
                                                "EvalMM")),
                                     # labels = c("Trained meta-mapping",
                                     #            "Held-out meta-mapping")),
                organizer = factor(interaction(mapping_toe, run_type),
                                   levels=c("TrainedMM.HoMM", "EvalMM.HoMM", "TrainedMM.Language"),
                                   labels=c("HoMM\n(trained MM)", "HoMM\n(Held-out MM)", "Language\ngeneralization"))),  
       aes(x=num_train_examples, 
           y=mean_accuracy, 
           linetype=organizer,
           color=organizer)) +
  annotate("text", x=3, y=0.47, alpha=0.5, label="Chance") +
  annotate("text", x=4.5, y=1.03, alpha=0.5, label="Optimal adaptation") +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_linerange(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1,
                position=position_dodge(0.8),
                show.legend=F) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1,
            position=position_dodge(0.8)) +
  geom_point(stat="summary",
             fun.y="mean",
             size=2.5,
             position=position_dodge(0.8),
             show.legend=F) +
  scale_color_manual(values=c("#e41a1c", "#e41a1c", "#477ec8")) +
  scale_linetype_manual(values=c(1, 2, 1)) +
  labs(x="Number of training meta-mappings\n(Approximate number of training concepts)", y="Adapted concept eval. accuracy") +
  scale_x_continuous(breaks = c(2, 4, 8, 12, 16),
                     labels = c("4\n(~110)", "8\n(~150)", "16\n(~200)", "24\n(~250)", "32\n(~300)")) +
  scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%")) + #, limits = c(0.8, NA)) +
  guides(color=guide_legend(title=NULL,
                            override.aes = list(shape=NA)),
         linetype=guide_legend(title=NULL)) +
  theme(legend.position=c(0.8, 0.31), legend.background=element_blank(), legend.box.background=element_blank(),
        legend.key.width = unit(1,"cm"))


ggsave("../../metamapping_paper/figures/concepts_adaptation_sweeping.png", width=4, height=3)
```


```{r}
ggplot(data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_eval",
                num_train_examples >= 200),
       aes(x=num_train_examples, 
           color=run_type,
           y=mean_accuracy)) +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
#  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_errorbar(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1,
                position=position_dodge(width=10)) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1,
            position=position_dodge(width=10)) +
  geom_point(stat="summary",
             fun.y="mean",
             size=4,
             position=position_dodge(width=10)) +
  scale_color_manual(values=c("#e41a1c", "#477ec8", "#984ea3")) +
  labs(x="Number of training concepts", y="Accuracy on evaluation tasks (held-out meta-mapping)") +
  # annotate("text", x=0.6, y=0.52, alpha=0.5, label="Chance") +
  # annotate("text", x=0.85, y=1.02, alpha=0.5, label="Optimal adaptation") +
  # annotate("path",x=c(1,1,1.95,1.95),y=c(1.05,1.08,1.08,1.05),alpha=0.5) +
  # annotate("text", x=1.5, y=1.1, alpha=0.5, label="n.s. (both perm- and t-test)") +
  # annotate("path",x=c(2.05, 2.05, 3, 3),y=c(1.05,1.08,1.08,1.05),alpha=0.5) +
  # annotate("text", x=2.5, y=1.1, alpha=0.5, label="p < 0.05 (both tests)") +
  scale_y_continuous(breaks = c(0.9, 1), labels = c("90%", "100%"), limits=c(0.9, NA))

#ggsave("../../../psych/dissertation/4-extending/figures/concepts_adaptation_sweeping_eval.png", width=6, height=4)
```

MM paper version:

```{r}
ggplot(data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_eval",
                run_type == "HoMM from language") %>%  # for fewer, we often don't have enough support for eval tasks, they're missing from most runs
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language\nGeneralization")),  
       aes(x=num_train_examples, 
           color=run_type, 
           y=mean_accuracy)) +
  annotate("text", x=15.5, y=0.53, alpha=0.5, label="Chance") +
  annotate("text", x=4.5, y=1.03, alpha=0.5, label="Optimal adaptation") +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  #geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_linerange(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1,
                position=position_dodge(0.4)) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1,
            linetype=2,
            position=position_dodge(0.4)) +
  geom_point(stat="summary",
             fun.y="mean",
             size=3,
             position=position_dodge(0.4)) +
  scale_color_manual(values=c("#e41a1c", "#477ec8")) +
  labs(x="Number of training meta-mappings\n(Approximate number of training concepts)", y="Adapted concept accuracy") +
  scale_x_continuous(breaks = c(2, 4, 8, 12, 16),
                     labels = c("4\n(~110)", "8\n(~150)", "16\n(~200)", "24\n(~250)", "32\n(~300)")) +
  scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%")) + #, limits = c(0.8, NA)) +
  guides(color=F)

ggsave("../../metamapping_paper/figures/concepts_adaptation_sweeping_eval.png", width=4, height=3)
```

## another visualization


```{r}
ggplot(data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train",
                run_type != "HoMM from examples") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language\nGeneralization")),  
       aes(x=mean_accuracy, 
           color=run_type)) +
  geom_density(adjust=0.9) +
  scale_color_manual(values=c("#e41a1c", "#477ec8")) +
  labs(x="Evaluation accuracy", y="Density of runs") +
  scale_x_continuous(breaks=c(0.75, 1.), labels=c("75%", "100%")) +
  guides(color=guide_legend(title=NULL)) +
  theme(legend.position=c(0.4, 0.12), legend.direction="horizontal") +#, legend.box.background=element_rect(), legend.box.margin=margin(1, 6, 6, 6))
  facet_grid(I(2*num_train_examples) ~ ., scales = "free")
ggsave("../../metamapping_paper/figures/concepts_adaptation_generalization_density.png", width=4, height=3)
```

```{r}
comparison_d = comparison_d %>%
  mutate(gets_it = (mean_accuracy > 0.99))
```


```{r}
ggplot(data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train" | run_type == "HoMM from language",
                run_type != "HoMM from examples") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language"),
                mapping_toe = factor(mapping_toe, levels = c("metamapping_is_train", "metamapping_is_eval"),
                                     labels = c("TrainedMM",
                                                "EvalMM")),
                # labels = c("Trained meta-mapping",
                #            "Held-out meta-mapping")),
                organizer = factor(interaction(mapping_toe, run_type),
                                   levels=c("TrainedMM.HoMM", "EvalMM.HoMM", "TrainedMM.Language"),
                                   labels=c("HoMM\n(trained MM)", "HoMM\n(Held-out MM)", "Language\ngeneralization"))),  
       aes(x=num_train_examples, 
           linetype=organizer,
           color=organizer,
           y=1. * gets_it)) +
  geom_linerange(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1,
                position=position_dodge(0.8)) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1,
            position=position_dodge(0.8)) +
  geom_point(stat="summary",
             fun.y="mean",
             size=3,
             position=position_dodge(0.8)) +
  labs(x="Number of training meta-mappings\n(Approximate number of training concepts)", y="Proportion of runs with\n>99% evaluation accuracy") +
  scale_y_continuous(breaks = c(0., 0.5, 1), labels = c("0/10", "5/10", "10/10")) + #, limits = c(0.8, NA)) +
  scale_color_manual(values=c("#e41a1c", "#e41a1c", "#477ec8")) +
  scale_linetype_manual(values=c(1, 2, 1)) +
  scale_x_continuous(breaks = c(2, 4, 8, 12, 16),
                     labels = c("4\n(~110)", "8\n(~150)", "16\n(~200)", "24\n(~250)", "32\n(~300)")) +
  guides(color=F,
         linetype=F) 
ggsave("../../metamapping_paper/figures/concepts_adaptation_proportion_perfect.png", width=4, height=3)
```


```{r}
glmer(gets_it ~ run_type + scale(num_train_examples) + (1|run),
      data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train",
                run_type != "HoMM from examples") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language\nGeneralization")),
      family="binomial") %>%
  summary()
```

```{r}
glmer(gets_it ~ run_type + (1|run),
      data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train",
                num_train_examples == 8,
                run_type != "HoMM from examples") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language\nGeneralization")),
      family="binomial") %>%
  summary()
```

```{r}
glmer(gets_it ~ run_type + (1|run),
      data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train",
                num_train_examples == 12,
                run_type != "HoMM from examples") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language\nGeneralization")),
      family="binomial") %>%
  summary()
```

Bootstrap by run
```{r message=FALSE, warning=FALSE}
set.seed(0)  # reproducibility
num_samples = 1000

boot_results = replicate(1000, data.frame())
data_by_run = list()
for (run_i in 1:num_runs) {
  data_by_run[[run_i]] = comparison_d %>% 
    filter(run == run_i - 1,
           mapping_toe == "metamapping_is_train",
           run_type != "HoMM from examples",
           num_train_examples == 8)
}

for (boot_i in 1:num_samples) {
  this_runs = sample(1:num_runs, num_runs, replace=T) 
  this_data = replicate(num_runs, data.frame())
  for (run_i in 1:num_runs) {
    this_data[[run_i]] = data_by_run[[this_runs[run_i]]] %>% 
      mutate(run = run_i)
  }
  this_data = bind_rows(this_data)
  
  these_results = tryCatch({
    glmer(gets_it ~ run_type + num_train_examples + (1|run),
          data=this_data,
          family="binomial") %>%
      summary()}, error = function(error){ return("Error")})
  if (these_results != "Error") {
    boot_results[[boot_i]] = data.frame(
      parameter=row.names(these_results$coefficients),
      estimate=these_results$coefficients[, 1],
      iteration=boot_i)
  }
}
boot_results = bind_rows(boot_results) 
```

```{r}
boot_results %>%
  filter(grepl("language", parameter)) %>%
  pull(estimate) %>%
  quantile(., probs=c(0.05, 0.95), na.rm=T)
```

