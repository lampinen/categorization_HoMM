---
title: "Category analysis"
author: "Andrew Lampinen"
output: html_document
---

```{r}
library(tidyverse)
library(lme4)
library(lmerTest)
```

# data loading

```{r}
parent_dir = "../categorization_HoMM_better_smaller_size_sweep"
subdirs = c(
            
            "results_nmappingsper_2",
            "results_nmappingsper_4",
            "results_nmappingsper_6",
            "results_nmappingsper_8",
            "results_nmappingsper_10",
            "results_nmappingsper_12",
            "results_nmappingsper_16"
            
            )

lang_subdirs = paste(subdirs, "language", sep="/")
lang_homm_subdirs = paste(subdirs, "language_HoMM", sep="/")
num_runs = 13
```

```{r}
read_config = function(config_file) { 
  config = read_delim(config_file, delim="\n") %>%
    separate(`key, value`, c("key", "value"), sep=",", extra="merge") %>%
    spread(key, value) %>%
    mutate_at(c("base_train_tasks", "base_eval_tasks", "meta_class_train_tasks", "meta_class_eval_tasks", "meta_map_train_tasks", "meta_map_eval_tasks"), function(x) {
      x = gsub("\\\"|[][]| |\'", "", x)
      return(str_split(x, ","))
    } )
}
```

```{r}
load_d = function(results_dir, result_subdirs, num_runs, file_type) {
  d = replicate(num_runs * length(result_subdirs), data.frame())
  index = 1
  for (run_i in 0:(num_runs-1)) {
    for (result_subdir in result_subdirs) {
      filename = sprintf("%s/%s/run%i_%s.csv", results_dir, result_subdir, run_i, file_type)
      print(filename)
      if (!file.exists(filename)) {
        print(paste("skipping ", filename, sep=""))
        next
      }
      if (grepl("config", file_type)) {
        this_d = read_config(filename)
      } else {
        this_d = read.csv(filename, check.names=F, header=T) 
        names(this_d) <- make.unique(names(this_d)) 

      }
      this_d = this_d %>%
        mutate(run = run_i,
               run_type = result_subdir)
      d[[index]] = this_d
      index = index + 1
    }
    
  }
  d = bind_rows(d)
  return(d)
}
```

```{r}
config_d = load_d(parent_dir, subdirs, num_runs, "run_config")
#loss_d = load_d(parent_dir, subdirs, num_runs, "losses")
lang_loss_d = load_d(parent_dir, lang_subdirs, num_runs, "language_losses")
#meta_true_d = load_d(parent_dir, subdirs, num_runs, "meta_true_losses")
lang_meta_true_d = load_d(parent_dir, lang_homm_subdirs, num_runs, "language_meta_true_losses")
```

# some manipulation

```{r}
# loss_d = loss_d %>%
#   filter(epoch %% 100 == 0) %>%
#   gather(task_and_train_or_eval, loss, -epoch, -run, -run_type) %>%
#   separate(task_and_train_or_eval, c("task", "train_or_eval"), sep=":") %>%
#   mutate(meta = grepl("is_|switch_|^NOT$", task),
#          accuracy = grepl("accuracy", task),
#          meta_task_type = case_when(!meta ~ "NA",
#                                     task == "NOT" ~ "NOT",
#                                     grepl("switch_color", task) ~ "switch_color",
#                                     grepl("switch_shape", task) ~ "switch_shape",
#                                     grepl("switch_size", task) ~ "switch_size"),
#          composite = ifelse(grepl("AND|OR|XOR", task), "composite", "basic"),
#          color_relevant = grepl("color", task),
#          shape_relevant = grepl("shape", task),
#          size_relevant = grepl("size", task),
#          num_train_examples = as.numeric(str_extract(run_type, "\\d+")),
#          train_or_eval=gsub("\\.\\d+", "", train_or_eval))
#   
```

```{r}
lang_loss_d = lang_loss_d %>%
  filter(epoch %% 500 == 0) %>%
  gather(task_and_train_or_eval, loss, -epoch, -run, -run_type) %>%
  separate(task_and_train_or_eval, c("task", "train_or_eval"), sep=":") %>%
  mutate(accuracy = grepl("accuracy", task),
         composite = ifelse(grepl("AND|OR|XOR", task), "composite", "basic"),
         composite_type = str_extract(task, "AND|OR|XOR"),
         color_relevant = grepl("color", task),
         shape_relevant = grepl("shape", task),
         size_relevant = grepl("size", task),
         num_train_examples = as.numeric(str_extract(run_type, "\\d+")),
         train_or_eval=gsub("\\.\\d+", "", train_or_eval))
```


```{r}
# meta_true_d = meta_true_d %>%
#   filter(epoch %% 100 == 0) %>%
#   gather(task, loss, -epoch, -run, -run_type) %>%
#   separate(task, c("meta_task", "mapping_toe", "base_task_toe", "source", "target"), ":|->") %>%
#   mutate(meta_task_type = case_when(meta_task == "NOT" ~ "NOT",
#                                     grepl("switch_color", meta_task) ~ "switch_color",
#                                     grepl("switch_shape", meta_task) ~ "switch_shape",
#                                     grepl("switch_size", meta_task) ~ "switch_size"),
#          base_task_type = case_when(grepl("AND|OR|XOR", source) ~ "composite",
#                                     T ~ "basic"),
#          base_composite_type = str_extract(source, "AND|OR|XOR"),
#          num_train_examples = as.numeric(str_extract(run_type, "\\d+")))
#   
```

```{r}
lang_meta_true_d = lang_meta_true_d %>%
  filter(epoch %% 500 == 0) %>%
  gather(task, loss, -epoch, -run, -run_type) %>%
  separate(task, c("meta_task", "mapping_toe", "base_task_toe", "source", "target"), ":|->") %>%
  mutate(meta_task_type = case_when(meta_task == "NOT" ~ "NOT",
                                    grepl("switch_color", meta_task) ~ "switch_color",
                                    grepl("switch_shape", meta_task) ~ "switch_shape",
                                    grepl("switch_size", meta_task) ~ "switch_size"),
         base_task_type = case_when(grepl("AND|OR|XOR", source) ~ "composite",
                                    T ~ "basic"),
         base_composite_type = str_extract(source, "AND|OR|XOR"),
         num_train_examples = as.numeric(str_extract(run_type, "\\d+")))

```

```{r}
theme_set(theme_classic())
```

```{r}
ggplot(lang_meta_true_d %>%
         filter(
           base_task_type == "composite",
           base_composite_type %in% c("AND", "XOR"),
           mapping_toe == "metamapping_is_train") %>%
         # at 16 examples per, run 3 is missing eval mapping XOR or AND tasks, and 4, 5 are missing both train and eval mapping tasks (because of sampling)
         # therefore we ran 3 additional runs with random seeds 10, 11, and 12, and replace appropriately
         filter(num_train_examples < 16 | !run %in% c(4, 5, 10)) %>%
         mutate(run = ifelse(run > 9, run - 7, run)),
       aes(x=epoch,
           y=loss,
           color=factor(base_task_toe, levels=c("example_is_train", "example_is_eval"), labels=c("Trained\ntarget", "Held-out\ntarget")))) +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1) +
  facet_grid(I(2*num_train_examples) ~ run) +
  scale_x_continuous(limits=c(0, 10000), breaks=c(0, 5000, 10000), labels=c("0", "5", "10")) +
  scale_y_continuous(breaks=c(0.5, 0.75, 1), labels=c("50%", "75%", "100%")) +
  scale_color_manual(values=c("#1b9e77", "#e7298a")) +
  labs(x="Epoch (thousands)", y="Average evaluation accuracy")+
  guides(color=guide_legend(title=NULL))

ggsave("../../metamapping_paper/figures/concepts_all_runs_train.png", width=8, height=5)
#ggsave("../../../psych/dissertation/4-extending/figures/concepts_all_runs_train.png", width=8, height=5)
```

```{r}
ggplot(lang_meta_true_d %>%
         filter(
                base_task_type == "composite",
                base_composite_type %in% c("AND", "XOR"),
                mapping_toe == "metamapping_is_eval",
                base_task_toe == "example_is_eval"
         ) %>%
         # at 16 examples per, run 3 is missing eval mapping XOR or AND tasks, and 4, 5 are missing both train and eval mapping tasks (because of sampling)
         # therefore we ran 3 additional runs with random seeds 10, 11, and 12, and replace appropriately
         filter(num_train_examples < 16 | !run %in% c(3, 4, 5)) %>%
         mutate(run = ifelse(run > 9, run - 7, run)),
       aes(x=epoch,
           y=loss,
           color=factor(base_task_toe, levels=c("example_is_train", "example_is_eval"), labels=c("Trained\ntarget", "Held-out\ntarget")))) +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1) +
  facet_grid(I(2*num_train_examples) ~ run) +
  scale_x_continuous(limits=c(0, 10000), breaks=c(0, 5000, 10000), labels=c("0", "5", "10")) +
  scale_y_continuous(breaks=c(0.5, 0.75, 1), labels=c("50%", "75%", "100%")) +
  scale_color_manual(values=c("#1b9e77", "#e7298a"), drop=F) +
  labs(x="Epoch (thousands)", y="Average evaluation accuracy")+
  guides(color=guide_legend(title=NULL))

ggsave("../../metamapping_paper/figures/concepts_all_runs_eval.png", width=8, height=5)
#ggsave("../../../psych/dissertation/4-extending/figures/concepts_all_runs_eval.png", width=8, height=5)
```

# comparison

Some tasks may not appear as result of meta-mapping
```{r}
target_tasks_by_run = bind_rows(
  lang_meta_true_d %>%
    filter(epoch == 0,
           base_task_toe == "example_is_eval",
           base_composite_type %in% c("AND", "XOR"), 
           !is.na(loss)) %>%
    mutate(num_train_examples = as.numeric(str_extract(run_type, "\\d+"))) %>%
    select(num_train_examples, run, mapping_toe, target) %>%
    rename(task=target)#,
  # meta_true_d %>%
  #   filter(epoch == 0,
  #          base_task_toe == "example_is_eval",
  #          base_composite_type %in% c("AND", "XOR"), 
  #          !is.na(loss)) %>%
  #   mutate(num_train_examples = as.numeric(str_extract(run_type, "\\d+"))) %>%
  #   select(num_train_examples, run, mapping_toe, target) %>%
  #   rename(task=target)
  )%>%
  distinct()
```

These results are robust to choice of test epoch (as long as it is large enough for learning to have asymptoted). Because different training sizes asymptote at different places, we test at a later epoch for smaller training sets.

```{r}
test_epoch = function(num_train_examples) {
  test_epoch = case_when(
    num_train_examples == 2 ~ 10000,
    num_train_examples %in% c(4, 6) ~ 7500,
    # num_train_examples == 8 ~ 5000,
    # num_train_examples == 12 ~ 5000,
    T ~ 5000
  ) 
  return(test_epoch)
}

comparison_d = bind_rows(lang_loss_d %>%
                           filter(accuracy,
                                  train_or_eval == "eval",
                                  composite == "composite",
                                  composite_type %in% c("AND", "XOR"),
                                  !is.na(loss)) %>%
                           filter(epoch == test_epoch(num_train_examples)) %>%
                           mutate(task = gsub("_accuracy", "", task)) %>%
                           select(epoch, run_type, num_train_examples, run, task, loss) %>%
                           inner_join(target_tasks_by_run) %>%
                           group_by(run_type, num_train_examples, mapping_toe, run, epoch) %>%
                           summarise(mean_accuracy = mean(loss, na.rm=T)) %>%
                           ungroup(),
#                          meta_true_d %>%
#                            filter(base_task_toe == "example_is_eval",
#                                   base_composite_type %in% c("AND", "XOR")) %>%
#                            filter(epoch == test_epoch(num_train_examples)) %>%
#                            group_by(run_type, num_train_examples, mapping_toe, run, epoch, target) %>%   # multiple mappings may produce same target                          
#                            summarise(accuracy = mean(loss, na.rm=T)) %>%
#                            group_by(run_type, num_train_examples, mapping_toe, run, epoch) %>%                           
#                            summarise(mean_accuracy = mean(accuracy, na.rm=T)) %>%
# #                           group_by(run_type, run) %>%
# #                           filter(mean_accuracy == max(mean_accuracy)) %>%
#                            ungroup(),
                         lang_meta_true_d %>%
                           filter(base_task_toe == "example_is_eval",
                                  base_composite_type %in% c("AND", "XOR")) %>%
                           filter(epoch == test_epoch(num_train_examples)) %>%
                           group_by(run_type, num_train_examples, mapping_toe, run, epoch, target) %>%   # multiple mappings may produce same target                          
                           summarise(accuracy = mean(loss, na.rm=T)) %>%
                           group_by(run_type, mapping_toe, run, epoch) %>%                           
                           summarise(mean_accuracy = mean(accuracy, na.rm=T)) %>%
                           ungroup()) %>%
  mutate(num_train_examples = as.numeric(str_extract(run_type, "\\d+")),
         run_type = case_when(grepl("language_HoMM", run_type) ~ "Lang_HoMM",
                              grepl("language", run_type) ~ "Lang",
                              T ~ "HoMM from examples"),
         run_type = factor(run_type,
                           levels=c("HoMM from examples", "Lang", "Lang_HoMM"),
                           labels=c("HoMM from examples", "Language", "HoMM from language")),
         ) %>%
  # at 16 examples per, run 3 is missing eval mapping XOR or AND tasks, and 4, 5 are missing both train and eval mapping tasks (because of sampling)
  # therefore we ran 3 additional runs with random seeds 10, 11, and 12, and replace appropriately
  filter(num_train_examples < 16 | run != 3 | mapping_toe == "metamapping_is_train",
         num_train_examples < 16 | run != 10 | mapping_toe == "metamapping_is_eval",
         num_train_examples < 16 | !run %in% c(4, 5)) %>%
  mutate(run = ifelse(run > 9, run - 7, run))
```


## main plots


MM paper version will not show examples comparions:

```{r}
ggplot(data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train",
                run_type != "HoMM from examples") %>%
         mutate(run_type = factor(run_type, levels=c("HoMM from language", "Language"), labels=c("Meta-mapping\n(from language)", "Language\nalone")),
                mapping_toe = factor(mapping_toe, levels = c("metamapping_is_train", "metamapping_is_eval"),
                                     labels = c("TrainedMM",
                                                "EvalMM")),
                                     # labels = c("Trained meta-mapping",
                                     #            "Held-out meta-mapping")),
                organizer = factor(interaction(mapping_toe, run_type),
                                   levels=c("TrainedMM.HoMM", "EvalMM.HoMM", "TrainedMM.Language"),
                                   labels=c("HoMM\n(trained MM)", "HoMM\n(Held-out MM)", "Language\ngeneralization"))),  
       aes(x=num_train_examples, 
           y=mean_accuracy, 
#           linetype=organizer,
           color=run_type)) +
#  annotate("text", x=3, y=0.47, alpha=0.5, label="Chance") +
  annotate("text", x=4.5, y=1.015, alpha=0.5, label="Optimal adaptation") +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
#  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_linerange(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1,
                position=position_dodge(0.8),
                show.legend=F) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1,
            position=position_dodge(0.8)) +
  geom_point(stat="summary",
             fun.y="mean",
             size=2.5,
             position=position_dodge(0.8),
             show.legend=F) +
  #scale_color_manual(values=c("#e41a1c", "#477ec8")) +
  scale_color_manual(values=c("#fec44f", "#02205b")) +
  scale_linetype_manual(values=c(1, 2, 1)) +
  labs(x="Number of training meta-mappings", y="Adapted concept eval. accuracy\n(trained meta-mappings)") +
  scale_x_continuous(breaks = c(2, 4, 6, 8, 10, 12, 16),
                     labels = c("4", "8", "12", "16", "20", "24", "32")) +
                     #labels = c("4\n(~110)", "8\n(~150)", "16\n(~200)", "24\n(~250)", "32\n(~300)")) +
  scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%")) + #, limits = c(0.8, NA)) +
  guides(color=guide_legend(title=NULL,
                            override.aes = list(shape=NA)),
         linetype=guide_legend(title=NULL)) +
  theme(legend.position=c(0.75, 0.31), legend.background=element_blank(), legend.box.background=element_blank(),
        legend.key.width = unit(1,"cm"),
        legend.key.height = unit(0.75, "cm"))


ggsave("../../metamapping_paper/figures/concepts_adaptation_sweeping.png", width=4, height=3)
#ggsave("../../../psych/dissertation/4-extending/figures/concepts_adaptation_sweeping.png", width=6, height=4)
```

```{r}
ggplot(data=comparison_d %>%
         filter(run_type == "HoMM from language") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language"),
                mapping_toe = factor(mapping_toe, levels = c("metamapping_is_train", "metamapping_is_eval"),
#                                     labels = c("TrainedMM",
#                                                "EvalMM")),
                                     labels = c("Trained",
                                                "Held-out"))),  
       aes(x=num_train_examples, 
           y=mean_accuracy, 
           linetype=mapping_toe,
           color=mapping_toe)) +
  annotate("text", x=2.8, y=0.48, alpha=0.5, label="Chance") +
  annotate("text", x=4.7, y=1.027, alpha=0.5, label="Optimal adaptation") +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_linerange(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1,
                #position=position_dodge(0.8),
                show.legend=F) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1,
            #position=position_dodge(0.8)
            ) +
  geom_point(stat="summary",
             fun.y="mean",
             size=2.5,
             #position=position_dodge(0.8),
             show.legend=F) +
  scale_color_manual(values=c("#984ea3", "#ff7f00")) +
  scale_linetype_manual(values=c("solid", "31")) +
  labs(x="Number of training meta-mappings", y="Adapted concept eval. accuracy\n(trained meta-mappings)") +
  scale_x_continuous(breaks = c(2, 4, 6, 8, 10, 12, 16),
                     labels = c("4", "8", "12", "16", "20", "24", "32")) +
                     #labels = c("4\n(~110)", "8\n(~150)", "16\n(~200)", "24\n(~250)", "32\n(~300)")) +
  scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%")) + #, limits = c(0.8, NA)) +
  guides(color=guide_legend(title="Meta-mapping",
                            override.aes = list(shape=NA)),
         linetype=guide_legend(title="Meta-mapping")) +
  theme(legend.position=c(0.84, 0.25), legend.background=element_blank(), legend.box.background=element_blank(),
        legend.key.width = unit(1,"cm"),
        legend.key.height = unit(0.5, "cm"))


ggsave("../../metamapping_paper/figures/concepts_adaptation_sweeping_nolang.png", width=4, height=3)
```

```{r}
ggplot(data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_eval",
                run_type == "HoMM from language") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language"),
                mapping_toe = factor(mapping_toe, levels = c("metamapping_is_train", "metamapping_is_eval"),
                                     labels = c("TrainedMM",
                                                "EvalMM")),
                                     # labels = c("Trained meta-mapping",
                                     #            "Held-out meta-mapping")),
                organizer = factor(interaction(mapping_toe, run_type),
                                   levels=c("TrainedMM.HoMM", "EvalMM.HoMM", "TrainedMM.Language"),
                                   labels=c("HoMM\n(trained MM)", "HoMM\n(Held-out MM)", "Language\ngeneralization"))),  
       aes(x=num_train_examples, 
           y=mean_accuracy, 
#           linetype=organizer,
           color=run_type)) +
  annotate("text", x=3, y=0.47, alpha=0.5, label="Chance") +
  annotate("text", x=4.5, y=1.03, alpha=0.5, label="Optimal adaptation") +
  geom_hline(yintercept=1, linetype=2, alpha=0.5) +
  geom_hline(yintercept=0.5, linetype=3, alpha=0.5) +
  geom_linerange(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1,
                position=position_dodge(0.8),
                show.legend=F) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1,
            linetype=2,
            position=position_dodge(0.8)) +
  geom_point(stat="summary",
             fun.y="mean",
             size=2.5,
             position=position_dodge(0.8),
             show.legend=F) +
  scale_color_manual(values=c("#e41a1c")) +
  scale_linetype_manual(values=c(1, 2, 1)) +
  labs(x="Number of training meta-mappings", y="Adapted concept eval. accuracy\n(held-out meta-mappings)") +
  scale_x_continuous(breaks = c(2, 4, 6, 8, 10, 12, 16),
                     labels = c("4", "8", "12", "16", "20", "24", "32")) +
                     #labels = c("4\n(~110)", "8\n(~150)", "16\n(~200)", "24\n(~250)", "32\n(~300)")) +
  scale_y_continuous(breaks = c(0.5, 0.75, 1), labels = c("50%", "75%", "100%")) + #, limits = c(0.8, NA)) +
  guides(color=F)
  # guides(color=guide_legend(title=NULL,
  #                           override.aes = list(shape=NA)),
  #        linetype=guide_legend(title=NULL)) +
  # theme(legend.position=c(0.8, 0.31), legend.background=element_blank(), legend.box.background=element_blank(),
  #       legend.key.width = unit(1,"cm"))


#ggsave("../../metamapping_paper/figures/concepts_adaptation_sweeping_eval.png", width=4, height=3)
#ggsave("../../../psych/dissertation/4-extending/figures/concepts_adaptation_sweeping_eval.png", width=6, height=4)
```

## another visualization


```{r}
ggplot(data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train",
                run_type != "HoMM from examples") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language\nGeneralization")),  
       aes(x=mean_accuracy, 
           color=run_type)) +
  geom_density(adjust=0.9) +
  scale_color_manual(values=c("#e41a1c", "#477ec8")) +
  labs(x="Evaluation accuracy", y="Density of runs") +
  scale_x_continuous(breaks=c(0.75, 1.), labels=c("75%", "100%")) +
  guides(color=guide_legend(title=NULL)) +
  theme(legend.position=c(0.4, 0.12), legend.direction="horizontal") +#, legend.box.background=element_rect(), legend.box.margin=margin(1, 6, 6, 6))
  facet_grid(I(2*num_train_examples) ~ ., scales = "free")
#ggsave("../../metamapping_paper/figures/concepts_adaptation_generalization_density.png", width=4, height=3)
```

```{r}
comparison_d = comparison_d %>%
  mutate(gets_it = (mean_accuracy > 0.99))
```


```{r}
ggplot(data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train",
                run_type != "HoMM from examples") %>%
         mutate(run_type = factor(run_type, levels=c("HoMM from language", "Language"), labels=c("Meta-mapping\n(from language)", "Language\nalone")),
                mapping_toe = factor(mapping_toe, levels = c("metamapping_is_train", "metamapping_is_eval"),
                                     labels = c("TrainedMM",
                                                "EvalMM")),
                # labels = c("Trained meta-mapping",
                #            "Held-out meta-mapping")),
                organizer = factor(interaction(mapping_toe, run_type),
                                   levels=c("TrainedMM.HoMM", "EvalMM.HoMM", "TrainedMM.Language"),
                                   labels=c("HoMM\n(trained MM)", "HoMM\n(Held-out MM)", "Language\ngeneralization"))),  
       aes(x=num_train_examples, 
#           linetype=organizer,
           color=run_type,
           y=1. * gets_it)) +
  geom_linerange(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                show.legend=F,
                size=1,
                position=position_dodge(0.8)) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1,
            position=position_dodge(0.8)) +
  geom_point(stat="summary",
             fun.y="mean",
             size=3,
             position=position_dodge(0.8)) +
  labs(x="Number of training meta-mappings", y="Proportion of runs with >99%\nevaluation accuracy (trained MMs)") +
  scale_x_continuous(breaks = c(2, 4, 6, 8, 10, 12, 16),
                     labels = c("4", "8", "12", "16", "20", "24", "32")) +
                     #labels = c("4\n(~110)", "8\n(~150)", "16\n(~200)", "24\n(~250)", "32\n(~300)")) +
  scale_y_continuous(breaks = c(0., 0.5, 1), labels = c("0/10", "5/10", "10/10")) + #, limits = c(0.8, NA)) +
  scale_color_manual(values=c("#fec44f", "#02205b")) +
  guides(color=guide_legend(title=NULL,
                            override.aes = list(shape=NA)),
         linetype=guide_legend(title=NULL)) +
  theme(legend.position=c(0.8, 0.2), legend.background=element_blank(), legend.box.background=element_blank(),
        legend.key.width = unit(1,"cm"))
ggsave("../../metamapping_paper/figures/concepts_adaptation_proportion_perfect.png", width=4, height=3)
#ggsave("../../../psych/dissertation/4-extending/figures/concepts_adaptation_proportion_perfect.png", width=4, height=3)
```

```{r}
ggplot(data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_eval",
                run_type == "HoMM from language") %>%
         mutate(run_type = factor(run_type, levels=c("HoMM from language", "Language"), labels=c("Meta-mapping\n(from language)", "Language\nalone")),
                mapping_toe = factor(mapping_toe, levels = c("metamapping_is_train", "metamapping_is_eval"),
                                     labels = c("TrainedMM",
                                                "EvalMM")),
                # labels = c("Trained meta-mapping",
                #            "Held-out meta-mapping")),
                organizer = factor(interaction(mapping_toe, run_type),
                                   levels=c("TrainedMM.HoMM", "EvalMM.HoMM", "TrainedMM.Language"),
                                   labels=c("HoMM\n(trained MM)", "HoMM\n(Held-out MM)", "Language\ngeneralization"))),  
       aes(x=num_train_examples, 
#           linetype=organizer,
           color=run_type,
           y=1. * gets_it)) +
  geom_linerange(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                size=1,
                position=position_dodge(0.8)) +
  geom_line(stat="summary",
            fun.y="mean",
            linetype=2,
            size=1,
            position=position_dodge(0.8)) +
  geom_point(stat="summary",
             fun.y="mean",
             size=3,
             position=position_dodge(0.8)) +
  labs(x="Number of training meta-mappings", y="Proportion of runs with >99%\nevaluation accuracy (held-out MMs)") +
  scale_y_continuous(breaks = c(0., 0.5, 1), labels = c("0/10", "5/10", "10/10"), limits = c(0, 1)) +
  scale_color_manual(values=c("#fec44f", "#02205b")) +
  #scale_color_manual(values=c("#e41a1c", "#477ec8")) +
#  scale_linetype_manual(values=c(1, 2, 1)) +
  scale_x_continuous(breaks = c(2, 4, 6, 8, 10, 12, 16),
                     labels = c("4", "8", "12", "16", "20", "24", "32")) +
  guides(color=F,
         linetype=F) 
ggsave("../../metamapping_paper/figures/concepts_adaptation_proportion_perfect_eval.png", width=4, height=3)
#ggsave("../../../psych/dissertation/4-extending/figures/concepts_adaptation_proportion_perfect_eval.png", width=4, height=3)
```

```{r}
glmer(gets_it ~ run_type * I(num_train_examples - 18) + (1|run:num_train_examples),
      data=comparison_d %>%
         filter(mapping_toe == "metamapping_is_train",
                run_type != "HoMM from examples") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language\nGeneralization")),
      family="binomial") %>%
  summary()
```

## revision nolang plot

```{r}
ggplot(data=comparison_d %>%
         filter(run_type == "HoMM from language") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language"),
                mapping_toe = factor(mapping_toe, levels = c("metamapping_is_train", "metamapping_is_eval"),
                                     labels = c("Trained",
                                                "Held-out"))),  
       aes(x=num_train_examples, 
           linetype=mapping_toe,
           color=mapping_toe,
           y=1. * gets_it)) +
  geom_linerange(stat="summary",
                fun.data="mean_cl_boot",
                width=0.25,
                show.legend=F,
                size=1,
                position=position_dodge(0.8)) +
  geom_line(stat="summary",
            fun.y="mean",
            size=1,
            position=position_dodge(0.8)) +
  geom_point(stat="summary",
             fun.y="mean",
             size=3,
             position=position_dodge(0.8)) +
  labs(x="Number of training meta-mappings", y="Proportion of runs with >99%\nevaluation accuracy (trained MMs)") +
  scale_color_manual(values=c("#984ea3", "#ff7f00")) +
  scale_linetype_manual(values=c("solid", "31")) +
  scale_x_continuous(breaks = c(2, 4, 6, 8, 10, 12, 16),
                     labels = c("4", "8", "12", "16", "20", "24", "32")) +
                     #labels = c("4\n(~110)", "8\n(~150)", "16\n(~200)", "24\n(~250)", "32\n(~300)")) +
  scale_y_continuous(breaks = c(0., 0.5, 1), labels = c("0/10", "5/10", "10/10")) + #, limits = c(0.8, NA)) +
  guides(color=guide_legend(title="Meta-mapping",
                            override.aes = list(shape=NA)),
         linetype=guide_legend(title="Meta-mapping")) +
  theme(#legend.position=c(0.75, 0.6), legend.background=element_blank(), legend.box.background=element_blank(),
        legend.key.width = unit(1,"cm"))
ggsave("../../metamapping_paper/figures/concepts_adaptation_proportion_perfect_nolang.png", width=5, height=3)
```

# Analyses on full comparison data


```{r}
unsummarized_comparison_d = bind_rows(lang_loss_d %>%
                             filter(accuracy,
                                    train_or_eval == "eval",
                                    composite == "composite",
                                    composite_type %in% c("AND", "XOR"),
                                    !is.na(loss)) %>%
                             filter(epoch == test_epoch(num_train_examples)) %>%
                             mutate(task = gsub("_accuracy", "", task)) %>%
                             select(epoch, run_type, num_train_examples, run, task, loss) %>%
                             inner_join(target_tasks_by_run) %>%
                             rename(accuracy=loss),
                         lang_meta_true_d %>%
                           filter(base_task_toe == "example_is_eval",
                                  base_composite_type %in% c("AND", "XOR")) %>%
                           filter(epoch == test_epoch(num_train_examples)) %>%
                           group_by(run_type, num_train_examples, mapping_toe, run, epoch, target) %>%   # multiple mappings may produce same target                          
                           summarise(accuracy = mean(loss, na.rm=T)) %>%
                           ungroup()) %>%
  mutate(num_train_examples = as.numeric(str_extract(run_type, "\\d+")),
         run_type = case_when(grepl("language_HoMM", run_type) ~ "Lang_HoMM",
                              grepl("language", run_type) ~ "Lang",
                              T ~ "HoMM from examples"),
         run_type = factor(run_type,
                           levels=c("HoMM from examples", "Lang", "Lang_HoMM"),
                           labels=c("HoMM from examples", "Language", "HoMM from language")),
         gets_it = accuracy == 1.
         ) %>%
  # at 16 examples per, run 3 is missing eval mapping XOR or AND tasks, and 4, 5 are missing both train and eval mapping tasks (because of sampling)
  # therefore we ran 3 additional runs with random seeds 10, 11, and 12, and replace appropriately
  filter(num_train_examples < 16 | run != 3 | mapping_toe == "metamapping_is_train",
         num_train_examples < 16 | run != 10 | mapping_toe == "metamapping_is_eval",
         num_train_examples < 16 | !run %in% c(4, 5)) %>%
  mutate(run = ifelse(run > 9, run - 7, run))
```

```{r}
lmer(accuracy ~ run_type * I(num_train_examples - 18)  + (1|run:num_train_examples),
      data=unsummarized_comparison_d %>%
         filter(mapping_toe == "metamapping_is_train") %>%
         mutate(run_type = ifelse(run_type == "HoMM from language", "HoMM", "Language"))) %>%
  summary()
```

